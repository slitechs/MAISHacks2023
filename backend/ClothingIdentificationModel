import keras
import tensorflow
from keras import layers
import zipfile
import os

from google.colab import files
from google.colab import drive
drive.mount('/content/drive/', force_remount=True)
os.chdir('/content/drive/MyDrive/DeepFashion2 Dataset')
for x in os.listdir():
  file_name = x
  pswd = '2019Deepfashion2**'

  with zipfile.ZipFile(file_name) as file:
      # password you pass must be in the bytes you converted 'str' into 'bytes'
      file.extractall(pwd = bytes(pswd, 'utf-8'), file_path="../Deep Fashion")

from tensorflow.keras.utils import image_dataset_from_directory
  
train_dataset = image_dataset_from_directory(
    new_base_dir / "train",
    image_size=(180, 180),
    batch_size=32)
validation_dataset = image_dataset_from_directory(
    new_base_dir / "validation",
    image_size=(180, 180),
    batch_size=32)
test_dataset = image_dataset_from_directory(
    new_base_dir / "test",
    image_size=(180, 180),
    batch_size=32)

data_augmentation = keras.Sequential(
    [
        layers.RandomFlip("horizontal"),
        layers.RandomRotation(0.1),
        layers.RandomZoom(0.1),
    ]
)

inputs = keras.Input(shape=(image_size))
plt.figure(figsize=(10, 10)) 
for images, _ in train_dataset.take(1):
    for i in range(9):
        augmented_images = data_augmentation(images)
        ax = plt.subplot(3, 3, i + 1)
        plt.imshow(augmented_images[0].numpy().astype("uint8"))
        plt.axis("off")


from re import X
def make_model(image_shape):
  conv_base = keras.applications.vgg16.VGG16(
    weights="imagenet",
    include_top=False,
    input_shape=(image_shape))
  
  conv_base.trainable = True
  for layer in conv_base.layers[:-2]:
    layer.trainable = False
  
  inputs = keras.Input(shape=(image_shape))
  x = conv_base(inputs)
  x = layers.Flatten()(x)
  x = layers.Dense(256)(x)
  x = layers.Dropout(0.5)(x)
  outputs = layers.Dense(1, activation="sigmoid")(x)
  model = keras.Model(inputs, outputs)
  return model


model = make_model(image_shape)

model.compile(optimizer="rmsprop", loss="sparse_categorical_crossentropy")
  
callbacks = [
    keras.callbacks.ModelCheckpoint("oxford_segmentation.keras",
                                    save_best_only=True)
]
  
history = model.fit(train_input_imgs, train_targets,
                    epochs=50,
                    callbacks=callbacks,
                    batch_size=64,
                    validation_data=(val_input_imgs, val_targets))
